#!/usr/bin/env python3
"""
Medium RSS feed'inden yazÄ±larÄ± Ã§ekip Jekyll formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
"""

import feedparser
import os
import re
import html2text
from datetime import datetime
from pathlib import Path
import frontmatter

# Medium kullanÄ±cÄ± adÄ±nÄ±zÄ± buraya yazÄ±n veya GitHub Secrets'tan alÄ±n
MEDIUM_USERNAME = os.environ.get('MEDIUM_USERNAME', 'msrexe')
MEDIUM_RSS_URL = f'https://medium.com/feed/@{MEDIUM_USERNAME}'
POSTS_DIR = Path('_posts')

def clean_filename(title):
    """BaÅŸlÄ±ktan geÃ§erli bir dosya adÄ± oluÅŸturur."""
    # TÃ¼rkÃ§e karakterleri deÄŸiÅŸtir
    replacements = {
        'Ä±': 'i', 'ÄŸ': 'g', 'Ã¼': 'u', 'ÅŸ': 's', 'Ã¶': 'o', 'Ã§': 'c',
        'Ä°': 'I', 'Ä': 'G', 'Ãœ': 'U', 'Å': 'S', 'Ã–': 'O', 'Ã‡': 'C'
    }
    for tr_char, en_char in replacements.items():
        title = title.replace(tr_char, en_char)
    
    # Ã–zel karakterleri temizle
    title = re.sub(r'[^\w\s-]', '', title)
    title = re.sub(r'[-\s]+', '-', title)
    return title.strip('-')

def extract_first_image(content):
    """Ä°Ã§erikten ilk resmi Ã§Ä±karÄ±r."""
    img_match = re.search(r'<img[^>]+src="([^">]+)"', content)
    if img_match:
        return img_match.group(1)
    return None

def html_to_markdown(html_content):
    """HTML iÃ§eriÄŸi Markdown'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    h = html2text.HTML2Text()
    h.ignore_links = False
    h.ignore_images = False
    h.ignore_emphasis = False
    h.body_width = 0  # SatÄ±r sarma yapma
    markdown = h.handle(html_content)
    
    # Gereksiz boÅŸluklarÄ± temizle
    markdown = re.sub(r'\n{3,}', '\n\n', markdown)
    return markdown.strip()

def extract_description(content, max_length=200):
    """Ä°Ã§erikten kÄ±sa bir aÃ§Ä±klama Ã§Ä±karÄ±r."""
    # HTML etiketlerini temizle
    text = re.sub(r'<[^>]+>', '', content)
    # Fazla boÅŸluklarÄ± temizle
    text = re.sub(r'\s+', ' ', text).strip()
    # Ä°lk cÃ¼mleyi veya max_length kadar karakteri al
    if len(text) > max_length:
        text = text[:max_length].rsplit(' ', 1)[0] + '...'
    return text

def get_existing_posts():
    """Mevcut post'larÄ±n Medium URL'lerini ve baÅŸlÄ±klarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."""
    existing_data = {
        'urls': set(),
        'titles': set(),
        'slugs': set()
    }
    
    if not POSTS_DIR.exists():
        POSTS_DIR.mkdir(parents=True)
        return existing_data
    
    for post_file in POSTS_DIR.glob('*.md'):
        try:
            post = frontmatter.load(post_file)
            # Medium URL'si varsa ekle
            if 'medium_url' in post.metadata:
                existing_data['urls'].add(post.metadata['medium_url'])
            # BaÅŸlÄ±k kontrolÃ¼
            if 'title' in post.metadata:
                existing_data['titles'].add(post.metadata['title'].lower().strip())
            # Slug kontrolÃ¼
            if 'slug' in post.metadata:
                existing_data['slugs'].add(post.metadata['slug'].lower().strip())
        except Exception as e:
            print(f"âš ï¸  {post_file} okunamadÄ±: {e}")
    
    return existing_data

def sync_medium_posts():
    """Medium RSS feed'inden yazÄ±larÄ± Ã§eker ve Jekyll formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    print(f"ğŸ“¡ Medium feed'i kontrol ediliyor: @{MEDIUM_USERNAME}")
    
    feed = feedparser.parse(MEDIUM_RSS_URL)
    
    if feed.bozo:
        print(f"âŒ RSS feed okunamadÄ±: {feed.bozo_exception}")
        return
    
    existing_data = get_existing_posts()
    new_posts_count = 0
    
    for entry in feed.entries:
        medium_url = entry.link
        title_lower = entry.title.lower().strip()
        clean_title = clean_filename(entry.title)
        slug = clean_title.lower()
        
        # Ã‡oklu kontrol: URL, baÅŸlÄ±k veya slug varsa atla
        if medium_url in existing_data['urls']:
            print(f"â­ï¸  Zaten mevcut (URL): {entry.title}")
            continue
        
        if title_lower in existing_data['titles']:
            print(f"â­ï¸  Zaten mevcut (BaÅŸlÄ±k): {entry.title}")
            continue
            
        if slug in existing_data['slugs']:
            print(f"â­ï¸  Zaten mevcut (Slug): {entry.title}")
            continue
        
        # Tarih bilgisini al
        published = datetime(*entry.published_parsed[:6])
        date_str = published.strftime('%Y-%m-%d')
        
        # Dosya adÄ±nÄ± oluÅŸtur
        clean_title = clean_filename(entry.title)
        filename = f"{date_str}-{clean_title}.md"
        filepath = POSTS_DIR / filename
        
        # Ä°Ã§eriÄŸi iÅŸle
        content = entry.get('content', [{}])[0].get('value', entry.get('summary', ''))
        markdown_content = html_to_markdown(content)
        
        # Ä°lk resmi bul
        first_image = extract_first_image(content)
        
        # AÃ§Ä±klama oluÅŸtur
        description = extract_description(content)
        
        # Kategori Ã§Ä±kar (Medium'da tags varsa)
        categories = [tag.term for tag in entry.get('tags', [])]
        category = categories[0].lower() if categories else 'general'
        
        # Front matter oluÅŸtur
        post_data = {
            'layout': 'post',
            'title': entry.title,
            'description': description,
            'category': category,
            'slug': clean_title.lower(),
            'author': 'msrexe',
            'medium_url': medium_url,
            'date': published,
            'lang': 'tr'  # Medium'dan gelen yazÄ±lar TÃ¼rkÃ§e
        }
        
        if first_image:
            post_data['image'] = first_image
        
        # Post'u oluÅŸtur
        post = frontmatter.Post(markdown_content, **post_data)
        
        # Dosyaya yaz
        with open(filepath, 'wb') as f:
            frontmatter.dump(post, f)
        
        print(f"âœ… Yeni yazÄ± eklendi: {filename}")
        new_posts_count += 1
    
    if new_posts_count == 0:
        print("â„¹ï¸  Yeni yazÄ± bulunamadÄ±.")
    else:
        print(f"ğŸ‰ {new_posts_count} yeni yazÄ± eklendi!")

if __name__ == '__main__':
    sync_medium_posts()
